% Load required themes and packages.
\documentclass{beamer}
\usepackage{mdframed}

\usetheme{Pittsburgh}
\usecolortheme{default}
\useinnertheme{default}
\useoutertheme{default}
\usefonttheme{structurebold}

% Import the necessary preamble for the document. 
\usepackage{../../proofsPrograms}

% Bibliography
\usepackage[style=verbose]{biblatex}
\addbibresource{../../proofsPrograms.bib} 
% In case of error: check the file path!
% the ../../ acts to jump back to files in path.
% Command line sequence:
%   pdflatex *filename* without .tex
%   biber *filename* without .bib
%   pdflatex *filename* without .tex

% Remove navigation bar
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{footline}[frame number]

% Definition format options. 
\newtheoremstyle{indentDefn}
{\topsep} % Space above
{\topsep} % Space below
{\it} % Body font
{2cm} % Indent amount
{\bf} % Theorem head font
{:} % Punctuation after theorem head
{0.5em} % Space after theorem head
{} % Theorem head spec

\theoremstyle{indentDefn} \newtheorem{defn}[]{Definition}

\title{Recursive Functions}
\author{MATH230}
\institute{Te Kura P\=angarau $\vert$ School of Mathematics and Statistics \\ Te Whare W\=ananga o Waitaha $\vert$ University of Canterbury}
\date{}

% Document body starts here.
\begin{document}


% Title frame
\begin{frame}

  \titlepage

\end{frame}

% Table of contents page
\begin{frame}
  \frametitle{Outline}

  \tableofcontents

\end{frame}

%%%%%%% Extras from 2023 %%%%%%%

% \section{G\"{o}del}

% \begin{frame}
% 	\frametitle{Meta Hopes and Dreams}
	
% 	Having now fixed a language and written down some axioms, we can revisit Hilbert's questions about mathematics. 
	
% 	\begin{itemize}
% 		\item Given a sentence $\phi$, is there a proof of $\phi$ or $\lnot \phi$ from the axioms? This is known as \textit{syntactic completeness}.
% 		\item Is the set of derivable formulae consistent? i.e. $\textnormal{PA} \vdash \bot$?
% 		\item Is there \textit{a} model? How many models are there? 
% 		\item Is the set of theorems decidable? 
% 	\end{itemize}

% 	Studying the answers to these questions in full detail is beyond the scope, and time limit, of this course. But these are the kind of questions one would learn about when studying this subject further. 
% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del's First Incompleteness Theorem}
	
% 	In 1931 G\"{o}del published the following theorem:
	
% 	\vspace{0.5cm}
	
% 	Any consistent formal theory $F$ within which Peano arithmetic can be carried out, is necessarily (syntactically) incomplete. That is, there are statements, $\phi$, in $F$ such that neither $F \vdash \phi$ nor $F \vdash \lnot \phi$. 
% 	% By Godels COMPLETENESS theorem we know this is the same as saying there exists a formula phi that is true but not provable. 
	
% 	\vspace{0.5cm} 
	
% 	Thus, Peano arithmetic is incomplete. 
	
% 	\vspace{0.5cm}
	
% 	Perhaps we can add axioms to PA to make it complete? No!  
	
% 	\vspace{0.5cm} 
	
% 	{\bf Peano arithmetic is incompletable!}
	
% \end{frame}

% \begin{frame}
% 	\frametitle{Paradoxical Inspiration}

% 	\begin{mdframed}
% 		\begin{center}
% 			This sentence is false. 
% 		\end{center}
% 	\end{mdframed}

% \end{frame}

% \begin{frame}
% 	\frametitle{Incompleteness Sketch}

% 	G\"{o}del proceeded accordingly: 

% 		\begin{itemize}
% 			\item Encoded wff and proofs using integers,
% 			\item (Carefully!) Defined predicates mimicking the liar paradox,
% 			\item Showed the predicates are primitive recursive, 
% 			\item Showed primitive recursive functions are representable \emph{in} Peano Arithmetic.
% 		\end{itemize}

% 	It's not enough to just mimic the Liar Paradox --- One has to do this with sentences \emph{in} Peano arithmetic. 

% 	Our approach here follows Peter Smith in ``An Introduction to G\"{o}del's Theorems"

% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del Numbering}

% 	In order to have wff (and proofs) in PA reference themselves, G\"{o}del encoded wff and proofs using natural numbers! 

% 	\begin{center}
% 		\begin{tabular}{ c c c c c c c c c c c c c c c c c c }
% 			$\lnot$ & $\land$ & $\lor$ & $\to$ & $\forall$ & $\exists$ & $=$ & $($ & $)$ & 0 & S & + & $\times$ & $x$ & $y$ & $z$ & $\dots$  \\
% 			\hline
% 			$1$ & $3$ & $5$ & $7$ & $9$ & $11$ & $13$ & $15$ & $17$ & $19$ & $21$ & $23$ & $25$ & $27$ & $2$ & $4$ & $6$ & $\cdots$ 
% 		\end{tabular}
% 	\end{center}

% 	$$ \forall \ x \ \lnot \ ( \ s \ ( \ x \ ) \ = \ 0 \ ) $$

% 	\vspace{3cm}

% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del Numbering: Proofs}

% 	Hilbert-Style proofs are linear, where natural deduction proof trees are not, but they prove exactly the same formulae. 

% 	\vspace{0.3cm}

% 	In such a proof system a proof is therefore a sequence of wff: 

% 	$$\mathcal{D}: \ \alpha_{1}, \alpha_{2}, \alpha_{3}, \alpha_{4}, \dots , \alpha_{c}$$

% 	\vspace{3cm}

% \end{frame}

% \begin{frame}
% 	\frametitle{Series of Functions}

% 	G\"{o}del then proceeds to define a series of (46) functions and predicates on G\"{o}del numbers so that he can encode the liar paradox in PA. For example he defines:  

% 	\begin{itemize}
% 		\item[1.] $x$ Div $y$ % x is divisible by y.
% 		\item[2.] Pr($n$) % the nth prime number.
% 		\item[12.] Var($x$) % x is a variable.
% 		\item[13.] Neg($x$) % Godel number of the negation.
% 		\item[32.] Impl($x$,$y$) % Godel number of x implies y. 
% 		\item[42.] Ax($x$) % x is an axiom.
% 		\item[45.] Proof($x$,$y$) % x is a proof of y. Godel: x B y.    
% 	\end{itemize}

% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del Sentence}

% 	For each well-formed formula $\varphi(y)$ with one-free variable, we define the diagonal of $\varphi(y)$ as follows: 

% 	$$\text{diag}(\varphi(y)) : \equiv \exists y \ (y = \text{gn}(\varphi(y)) \land \varphi(y))$$

% 	\vspace{3cm}
% 	% What does it look like for an integer to satisfy this? 

% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del Sentence}

% 	With all the required parts defined G\"{o}del combined them together in these final three definitions: 

% 	\begin{align*}
% 		\text{G\"{o}del}(x,y) &:\equiv \text{holds if x is a proof of diag(y)} \\
% 			% Properly: when x is the Godel number of a proof of the diagnolisation of the well-formed formula with godel number y. 
% 		U(y) &:\equiv \forall x \lnot \text{G\"{o}del}(x,y) \\
% 			% This holds if there is no proof of the diagonal of y. 
% 		G &:\equiv \exists y \ (y = \text{gn}(U(y)) \land U(y))
% 			% G is the diagonal of U. `'
% 	\end{align*}

% 	The sentence $G$, which we will call the G\"{o}del sentence is the diagonal of $U(y)$. 
	
% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del Sentence}

% 	The G\"{o}del sentence is equivalent to 

% 	$$ \forall x \ \lnot \text{G\"{o}del}(x, \text{gn}(U(y)))$$

% 	Which claims that there is no proof of the diagonal of $U(y)$. In other words, it claims of itself that it can't be proved!
	
% 	Therefore, $G$ is true if and only if it can't be proved!
% 	% In this way Godel has copied the liar paradox!

% \end{frame}

% \begin{frame}
% 	\frametitle{Undecidable Sentence}

% 	If $G$ could be proved in PA, then we would have a proof of a falsehood which we know (G\"{o}del also proved this) is impossible - natural deductions don't prove false claims!
	
% 	$$\PA \ \cancel{\vdash} \ G$$ 

% 	On the other hand, this means $G$ is true and hence $\lnot G$ is false. 
	
% 	$$\PA \ \cancel{\vdash} \ \lnot G$$ 

% 	Therefore there is a sentence that can neither be proved, nor refuted. 

% \end{frame}

% \begin{frame}
% 	\frametitle{Peano Arithmetic}

% 	Thus far we have shown there is a statement for which neither it, nor its negation, can be proved. However, it remains to say why this formula is \emph{in Peano arithmetic}. 

% 	\vspace{0.3cm}

% 	G\"{o}del was careful to show that these formulae/predicates/functions can be written in a \emph{finite} and \emph{computable} manner. For he showed that any such finite function could be represented \emph{in} Peano arithmetic. 
% 	% Not only is this work a magnificent piece of mathematics... 
% 	% It is (one of) the first examples of someone doing programming!

% 	\vspace{0.3cm}
	
% 	G\"{o}del showed that each of the functions and predicates could be written using a fixed syntax. Nowadays we might say he wrote them all in a specific programming language!

% \end{frame}

% \section{Primitive Recursion}

% \begin{frame}
% 	\frametitle{Primitive Recursion}

% 	Primitive recursive functions $f: \mathbb{N}^{k} \rightarrow \mathbb{N}$ are built from the following basic functions. 

% 	\vspace{0.5cm}

% 	\begin{itemize}
% 		\item[] Zero: $Z(n) = 0$
% 		\item[] Successor: $Succ(n) = s(n)$
% 		\item[] Projections: $\pi_{i}^{k}(x_{1},\dots, x_{i},\dots x_{k}) = x_{i}$
% 	\end{itemize}

% 	\vspace{0.3cm}

% 	These are chosen as there is no questioning the computability of these functions. In all cases it's clear what the output should be.

% 	\vspace{0.3cm}

% 	More sophisticated primitive recursive functions are built inductively from these initial functions according to finitely many applications of function composition and recursion. 

% \end{frame}

% \begin{frame}
% 	\frametitle{Function Composition}

% 	If $g:\mathbb{N}^{m} \rightarrow \mathbb{N}$ is primitive recursive and $h_{1},\dots, h_{m}: \mathbb{N}^{k} \rightarrow \mathbb{N}$ are each primitive recursive, then the function $f:\mathbb{N}^{k} \rightarrow \mathbb{N}$ defined by function composition 

% 	$$f({\bf x}) = g(h_{1}({\bf x}),\dots , h_{m}({\bf x}))$$

% 	is a primitive recursive function. 

% 	\vspace{0.5cm}

% 	{\bf Example}
% 	% Constant functions. 
% 	\vspace{4cm}

% \end{frame}

% \begin{frame}
% 	\frametitle{Recursion: Single Variable}

% 	If $g$ is a primitive recursive function and $d \in \mathbb{N}$, then the function $f:\mathbb{N} \rightarrow \mathbb{N}$ defined by 

% 	$$f(0) = d$$
% 	$$f(s(n)) = g(f(n),n)$$

% 	is also primitive recursive. 

% 	\vspace{0.5cm}

% 	{\bf Example}
% 	% Sum as a function of one variable: base case is variable held constant. 
% 	\vspace{4cm}

% \end{frame}

% \begin{frame}
% 	\frametitle{Multiplication and Exponentiation}

% 	Provide recursive definitions of multiplication and exponentiation.

% 	\vspace{7cm}
	
% \end{frame}

% \begin{frame}
% 	\frametitle{Recursion: Multiple Variable}

% 	If $g,h$ are primitive recursive functions of multiple variables, then the following function 

% 	$$f(0,{\bf x}) = g({\bf x})$$
% 	$$f(s(n),{\bf x}) = h(f(n,{\bf x}),n,{\bf x})$$

% 	is also primitive recursive. 

% 	% Here {\bf x} represents a finite list of values. 

% 	\vspace{5cm}

% \end{frame}

% \begin{frame}
% 	\frametitle{Primitive Recursion and Peano}

% 	Primitive recursive functions and predicates are all representable \emph{in} the first order language \emph{Peano arithmetic}.

% 	\vspace{0.3cm}

% 	Therefore the G\"{o}delian sentence is (representable) in PA and therefore is an example of a wff in PA for which neither it, nor its negation, can be proved. 

% \end{frame}

% \begin{frame}
% 	\frametitle{Prove consistency?}

% 	We want to prove some first-order theory $\mathcal{T}$ is consistent. 
	
% 	Hilbert hoped this proof would be finitary - i.e. be of the form we have been studying. It will therefore be a theorem of some other first-order theory $\mathcal{T}'$. We call this the meta-theory; the theory we use to talk about $\mathcal{T}$. Is $\mathcal{T}'$ consistent? Prove that in $\mathcal{T}''$

% 	This process keeps going until we get a theory we can trust. % PA!

% 	If we trust PA, then can we use it to prove stronger theories are consistent? Can we bootstrap consistency proofs of strong theories from the seemingly trustworthy PA? 

% 	For more on this see: J Hamkins, Lectures on the Philosophy of Mathematics.
	
% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del's Second Incompleteness Theorem}
	
% 	In 1931 G\"{o}del published the following theorem:
	
% 	\vspace{0.5cm}
	
% 	For any consistent formal theory $F$ within which Peano arithmetic can be carried out, the consistency of $F$ cannot be proved in $F$ itself. 
	
% 	\vspace{0.5cm} 
	
% 	Thus, Peano arithmetic can't prove its own consistency. Perhaps more importantly, we can't use it to prove any richer theory is consistent.
	
% 	\vspace{0.5cm} 
	
% 	G\"{o}del showed that any finite-type proof of consistency of PA can be written in PA and is one of those G\"{o}delian sentences!

%   % This might seem odd: why would we hope that it could prove its own consistency? 
%   % What Hilbert hoped for was some "finitary" proof of consistency. What Godel has shown is that any such proof could be encoded in PA: using Godel numbering etc. Therefore, if there were a finite proof in some first-order theory, then PA would witness it. But PA can't witness it! So there can't be one! 
	
% \end{frame}

% \begin{frame}
% 	\frametitle{G\"{o}del and Hilbert}

% 	G\"{o}del showed that PA is incompletable and that we can't have a finitary proof that PA, nor any richer theory, is consistent! 
	
% 	Two-thirds of Hilbert's program shown to be impossible! 

% 	\vspace{0.5cm}

% 	G\"{o}del's incompleteness theorems do not rule out the possibility that PA is decidable. That is, the existence of an algorithm that would decide - Yes or No - the answer to whether $\PA \vdash \alpha$ or $\PA \vdash \lnot\alpha$. 
% 	% What would an algorithm do with a Godel sentence? Return No in both cases.

% 	Therefore, it remains for us to explore the question of the decidability by an algorithm of PA. Whether there is an algorithm that can decide if a given wff is a theorem!

% 	{\bf Question: What is an algorithm?}

% \end{frame}

% \begin{frame}
% 	\frametitle{Effective Procedure as Recursion}

% 	G\"{o}del suggested one interpretation of what it means for a procedure to be effective; if there exists a primitive recursive function that computes the output.

% 	\vspace{0.5cm}

% 	Is this the correct notion of algorithm? What would it mean for it to be the correct definition for an algorithm? Are there other ideas? If so, then how do the other ideas relate to each other? 

% 	{\bf These are the questions that we will explore the remainder of the course.}

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Entscheidungsproblem}

\begin{frame}
  \frametitle{Entscheidungsproblem}

	In 1928 David Hilbert asked if there could be an ``effective procedure" that could decide (Yes/No) whether a sentence of first-order logic is a theorem. 

	\vspace{0.5cm}

	Furthermore, he asked if there could be such a procedure that could determine whether a sentence is a theorem of some first-order theory of mathematics.

	\vspace{0.5cm}
 
  	With the formal language written down, we now turn to the idea of an ``effective procedure" or ``algorithm". In order to say whether such a thing exists, we must be precise about what we mean. 

\end{frame}

\begin{frame}
	\frametitle{G\"{o}del/ASCII/Unicode}

	We introduced G\"{o}del numbering as a way of counting the wff of a first-order theory with countably many variables and a finite signature. However, G\"{o}del originally introduced the idea in his proof of the incompleteness theorems. 

	\vspace{0.5cm}

	G\"{o}del did more than just show that there is \emph{some} sentence for which it (and it's negation) can't be proved. He gave an effective procedure for generating such a sentence that one could get their hands on. 

	\vspace{0.5cm}

	G\"{o}del numbering was his way to make wff into objects of computation.

	\vspace{0.5cm}

	Rather than manipulating strings with some rules of computation, G\"{o}del turned the problem into manipulating numbers with some rules of computation.
\end{frame}

\begin{frame}
	\frametitle{Numbers}

	We will focus on computations with numbers. Most commonly (in mathematics) we use the decimal system (powers of 10) to represent numbers. However, numbers can be represented as sums of powers of different bases. 

	\vspace{0.5cm}

	For example 

	\vspace{0.1cm}

	\begin{itemize}

		\item (Decimal) $123_{10} = 1\times 10^{2} + 2\times 10^{1} + 3\times 10^{0}$ \vspace{0.5cm}

		\item (Binary) $123_{10} = 1111011_{2}$
		
		$1\times 2^{6} + 1\times 2^{5} + 1\times 2^{4} + 1\times 2^{3} + 0\times 2^{2} + 1\times 2^{1} + 1\times 2^{0}$ \vspace{0.5cm}

		\item (Unary) $123_{10} = 11111 \cdots 1111_{1}$
		
		$1\times 1^{123} + 1\times 1^{122} + \cdots + 1\times 1^{1} + 1\times 1^{0}$
	\end{itemize}

\end{frame}

\begin{frame}
	\frametitle{Computation?}

	What should we mean by an ``effective procedure"? What properties do we think such a procedure should have? 

	\vspace{6cm}

\end{frame}

\section{Primitive Recursion}

\begin{frame}
	\frametitle{Primitive Recursion: Initial Functions}

	Primitive recursive functions $f: \mathbb{N}^{k} \rightarrow \mathbb{N}$ are built from the following basic functions. 

	\vspace{0.5cm}

	\begin{itemize}
		\item[] Zero: $Z(n) = 0$
		\item[] Successor: $Succ(n) = s(n)$
		\item[] Projections: $\pi_{i}^{k}(x_{1},\dots, x_{i},\dots x_{k}) = x_{i}$
	\end{itemize}

	\vspace{0.5cm}

	These are chosen as there is no questioning the computability of these functions. In all cases it's clear what the output should be. 

	\vspace{0.5cm}

	More sophisticated primitive recursive functions are built inductively from these initial functions according to finitely many applications of function composition and recursion. 

\end{frame}

\begin{frame}
	\frametitle{Function Composition}

	If $g:\mathbb{N}^{m} \rightarrow \mathbb{N}$ is primitive recursive and $h_{1},\dots, h_{m}: \mathbb{N}^{k} \rightarrow \mathbb{N}$ are each primitive recursive, then the function $f:\mathbb{N}^{k} \rightarrow \mathbb{N}$ defined by function composition 

	$$f({\bf x}) = g(h_{1}({\bf x}),\dots , h_{m}({\bf x}))$$

	is a primitive recursive function. 

	\vspace{0.5cm}

	{\bf Example}
	% Constant functions. 
	\vspace{4cm}

\end{frame}

\begin{frame}
	\frametitle{Recursion: Single Variable}

	If $g$ is a primitive recursive function and $d \in \mathbb{N}$, then the function $f:\mathbb{N} \rightarrow \mathbb{N}$ defined by 

	$$f(0) = d$$
	$$f(s(n)) = g(f(n),n)$$

	is also primitive recursive. 

	\vspace{0.5cm}

	{\bf Example}
	% Sum as a function of one variable: base case is variable held constant. 
	\vspace{4cm}

\end{frame}

\begin{frame}
	\frametitle{Multiplication and Exponentiation}

	Provide recursive definitions of multiplication and exponentiation.

	\vspace{7cm}
	
\end{frame}

\begin{frame}
	\frametitle{Recursion: Multiple Variable}

	If $g,h$ are primitive recursive functions of multiple variables, then the following function 

	$$f(0,{\bf x}) = g({\bf x})$$
	$$f(s(n),{\bf x}) = h(f(n,{\bf x}),n,{\bf x})$$

	is also primitive recursive. 

	% Here {\bf x} represents a finite list of values. 

	\vspace{5cm}

\end{frame}

\begin{frame}
	\frametitle{Effective Procedure as Recursion}

	One interpretation of what it means for a procedure to be effective, is if there exists a primitive recursive function that computes the output.

	\vspace{0.5cm}

	It's up to us to combine the initial components by composition and recursion to see how powerful this family of functions is. 

	\vspace{5cm}

\end{frame}

\section{Examples}

\begin{frame}
	\frametitle{Predecessor}

	Show that the predecessor function is primitive recursive.

	\vspace{7cm}

	% Define the function in some way first. Needs to be clear what output should be. 
	% P(s(n)) = pi_{2}(P(n),n)
	% Explain the difference between the informal and formal definition here. 
	% Happy with the informal. Better to give formal if you can. 

\end{frame}

\begin{frame}
	\frametitle{Limited Subtraction (Monus)}

	Show that limited subtraction is primitive recursive. 

	\vspace{7cm}

	% ld(x,s(n)) = g(ld(x,n),n)
	% g = Pred \circ proj_1 

\end{frame}

\begin{frame}
	\frametitle{Zero Test}

	The zero test is primitive recursive. 

	\vspace{7cm}

	% Piece wise function: 1 on 0 and 0 otherwise. 
	% Get the class to do this one. 
	% ld(1,n)

\end{frame}

\begin{frame}
	\frametitle{Signature}

	The non-zero test, or signature function, is primitive recursive. 

	\vspace{7cm}

	% limited difference of the previous


\end{frame}

\begin{frame}
	\frametitle{Absolute Difference}

	The absolute difference is primitive recursive. 

	\vspace{7cm}

	% Give hints by using a sum of all possible values and conditions (signature of difference) to 0 out all the terms not wanted in a sum.
	% This function is obtained by composition. No need for multiplication of conditions here. 
	% Although could be good to illustrate with this example. 


\end{frame}

\begin{frame}
	\frametitle{Min, Max}

	Min (or max) of two variables is primitive recursive. 

	\vspace{7cm}

	% Same idea as previous. Use signature to pickout the min or max. 


\end{frame}

\begin{frame}
  \frametitle{Piecewise Functions}

	If the primitive recursive functions are to be able to perform all possible computations, then we need to be able to write functions that can deal with conditional branching. 

	\vspace{0.5cm}

			$f(n) = \begin{cases}
				3n+1 & n \text{ odd} \\
				\frac{n}{2} & n \text{ even}
			\end{cases}$

			\hspace{1cm}

			% Explain that this amounts to if, (elif,) then, else branching in modern programming. 

			% This requires (i) predicates that are primitive recursive (ii) the ability to branch according to the output of the predicates. 

	\vspace{5cm}

\end{frame}

\begin{frame}
	\frametitle{Addition of Recursive Functions}

	Given two functions $f_{1},f_{2}$, we can define the point-wise sum of these functions as follows 

	$$(f_{1} + f_{2})(n) = f_{1}(n) + f_{2}(n)$$
	
	% if original functions are pr, then so is this sum. This is just a composition of pr functions! 
	% Can give a recursive definition if it's the same function. 

	\vspace{6cm}

\end{frame}

\begin{frame}
	\frametitle{Addition of Recursive Functions}

	Given functions $f_{1},f_{2},f_{3}$, we can define the point-wise sum of these functions as follows 

	$$(f_{1} + f_{2} + f_{3})(n) = f_{1}(n) + f_{2}(n) + f_{3}(n)$$
	
	% Use brackets to show that this is primitive recursive based on the previous slide. 
	% So, in fact, any finite sum of primitive recursive functions are primitive recursive. 

	\vspace{6cm}

\end{frame}

\begin{frame}
	\frametitle{Addition of Recursive Functions}

	Given a primitive recursive function $f$, we can define the point-wise sum of the function with itself finitely many times as follows 

	$$(f + \dots + f)(n) = f(n) + \dots + f(n)$$
	
	% Although the composition still works, we can give a recursive definition if it's the same function.
	
	% (Sigma f)(x,n) = (i) 0 if n = 0 (ii) sum(f(x), (sigma f)(x,n-1))

	\vspace{6cm}

\end{frame}

\begin{frame}
	\frametitle{Multiplication of Recursive Functions}

	Given two functions $f_{1},f_{2}$, we can define the point-wise multiplication of these functions as follows 

	$$(f_{1} \cdot f_{2})(n) = f_{1}(n) \cdot f_{2}(n)$$
	
	% if original functions are pr, then so is this sum. This is just a composition of pr functions! 
	% Can give a recursive definition if it's the same function. 

	\vspace{6cm}

\end{frame}

\begin{frame}
	\frametitle{Multiplication of Recursive Functions}

	Given functions $f_{1},f_{2},f_{3}$, we can define the point-wise product of these functions as follows 

	$$(f_{1} \times f_{2} \times f_{3})(n) = f_{1}(n) \times f_{2}(n) \times f_{3}(n)$$
	
	% Use brackets to show that this is primitive recursive based on the previous slide. 
	% So, in fact, any finite product of primitive recursive functions are primitive recursive. 

	\vspace{6cm}

\end{frame}


\begin{frame}
	\frametitle{Multiplication of Recursive Functions}

	Given a primitive recursive function $f$, we can define the point-wise product of the function with itself finitely many times as follows 

	$$(f \times \dots \times f)(n) = f(n) \times \dots \times f(n)$$
	
	% if original functions are pr, then so is this sum. This is just a composition of pr functions! 
	% Can give a recursive definition if it's the same function. 

	% (PI f)(x,n) = (i) 1 if n = 0 (ii) prod(f(x), (PI f)(x,n-1))

	\vspace{6cm}

\end{frame}

\begin{frame}
	\frametitle{Recursive Predicates}	

	In order to write conditional functions, we need to be able to compute whether the conditions are satisfied i.e. we need primitive recursive definitions of the conditions. 

	\vspace{0.5cm}

	We define the characteristic function of an $n$-ary predicate $P({\bf x})$

	\vspace{0.5cm}

	$$\chi_{P}({\bf x}):= \begin{cases}
		1 \hspace{0.5cm} \text{ if } P({\bf x})\\
		0 \hspace{0.5cm} \text{ if } \lnot P({\bf x})
	\end{cases} $$

	We say an $n$-ary predicate is primitive recursive if $\chi_{P}$ is primitive recursive. 

	\vspace{5cm}

\end{frame}

\begin{frame}
	\frametitle{Primitive Recursive Predicates}

	Conditional programs (piece-wise functions) may branch according to the values of the following predicates

	\vspace{0.5cm}

	\begin{itemize}
		\item Less than, less than or equal to (order)
		\item Greater than, greater than or equal to (order)
		\item Equal (identity)
	\end{itemize}

	\vspace{5cm}

\end{frame}

\begin{frame}
	\frametitle{Propositional Connectives}

	Suppose $P({\bf x})$ and $Q({\bf x})$ are two primitive $n$-ary recursive predicates.

	\vspace{0.5cm}

	Show that the following are all primitive recursive

	\begin{itemize}
		\item[] $\lnot P({\bf x})$
		\item[] $P({\bf x}) \lor Q({\bf x})$ 
		\item[] $P({\bf x}) \land Q({\bf x})$ 
		\item[] $P({\bf x}) \to Q({\bf x})$
	\end{itemize}

	\vspace{3.8cm}

	\hspace{6cm} {\bf Details left for tutorial.}

\end{frame}



\begin{frame}
	\frametitle{Conditional Functions}

	We may combine the addition, multiplication, and primitive recursive predicates to obtain conditional functionality. 

	\vspace{7cm}

\end{frame}

\begin{frame}
	\frametitle{Conditional Functions}

	Suppose we have $k$ distinct $n$-ary primitive recursive predicates $A_{1}, A_{2},\dots , A_{k}$ such that each ${\bf x}$ satisfies precisely one of them. We can use such a family of predicates to define piece-wise functions

	\vspace{0.5cm}

	$$g({\bf x}):= \chi_{A_{1}}({\bf x}) \cdot f_{1}({\bf x}) + \chi_{A_{2}}({\bf x}) \cdot f_{2}({\bf x}) + \cdots + \chi_{A_{k}}({\bf x}) \cdot f_{k}({\bf x})$$

	\vspace{6cm}


\end{frame}


\begin{frame}
	\frametitle{Existential Quantifier}

	If $Q(x)$ is a primitive recursive predicate, then bounded search for an integer that satisfies it is primitive recursive. That is to say, the following is primitive recursive.

	$$\chi_{\exists y < n Q(y)} =  \begin{cases}
		1 \hspace{0.5cm} \text{ if there exists } y < n \text{ such that } Q(y).\\
		0 \hspace{0.5cm} \text{ otherwise. }
	\end{cases}   $$

	\vspace{0.5cm}

	Bounded existential quantification is primitive recursive.

	\vspace{3cm}
	% Bounded summation + non-zero test. 

\end{frame}

\begin{frame}
	\frametitle{Example}

	 $\text{div}(x,y) = 
	 \begin{cases}
		1 & \text{ if } x\mid y. \\
		0 & \text{ otherwise. }
	 \end{cases}$
	
	\vspace{6cm}

	\hspace{6cm} {\bf Details left for tutorial.}

\end{frame}


\begin{frame}
	\frametitle{Universal Quantifier}

	If $Q(x)$ is a primitive recursive predicate, then checking if all integers less than a specified bound satisfy it is a primitive recursive process. 

	$$\chi_{\forall y < n Q(y)} =  \begin{cases}
		1 \hspace{0.5cm} \text{ if all } y < n \text{ satisfy } Q(y).\\
		0 \hspace{0.5cm} \text{ otherwise.}
	\end{cases}   $$

	\vspace{0.5cm}

	Bounded universal quantification is primitive recursive.

	\vspace{3cm}
	% Bounded product + non-zero test. 


\end{frame}

\begin{frame}
	\frametitle{Example}

	 $\text{prime?}(x) = \begin{cases}
		1 & \text{ if } x \text{ is prime.} \\
		0 & \text{ otherwise.}
	 \end{cases}$
	
	\vspace{6cm}

	\hspace{6cm} {\bf Details left for tutorial.}

\end{frame}

\begin{frame}
	\frametitle{Primitive Recursion Language}

	In a sense we are defining a (programming?) language for a certain class of functions. We are allowed to use the following functions and constructions to build new ones: 

	\vspace{0.5cm}

	\begin{itemize}
		\item[] Constants
		\item[] Projections 
		\item[] Arithmetic functions 
		\item[] Sums and products of functions
		\item[] $\sum_{y<n}$ and $\prod_{y<n}$
		\item[] Predicates 
		\item[] Propositional logic 
		\item[] Bounded quantification
	\end{itemize}

	\vspace{0.5cm}

	Which mathematical questions can be answered with such functions? 

\end{frame}

\begin{frame}
	\frametitle{Bounded Search}

	Continuing on from the definitions of bounded existential and bounded universal quantification, we introduce a new symbol $\mu$ for constructing functions of the form 

	$$\mu t < y P({\bf x,t}) = \text{ Smallest } t < y \text{ for which } P({\bf x},t) =1 $$ 

	So the $\mu$ operator takes in a predicate and a bound, and {\bf defines a function} which returns the smallest $t$ which satisfies the predicate. If there is no such $t$, then the function should return the bound $y$. 

	\vspace{0.5cm}

	{\bf Example} Smallest prime less than $y$ and greater than $x$. 

	$f(x,y) = \mu t < y [(t \text{ prime}) \land (x < t)]$

	$$f(6,4) = 4$$ 
	$$f(4,6) = 5$$

\end{frame}

\begin{frame}
	\frametitle{$\mu t < y$ is Primitive Recursive}

	Bounded minimisation of a primitive recursive predicate is primitive recursive. Idea: count failures up from 0.

	\vspace{0.5cm}

	{\bf Example}

	$P(x)$ is a predicate such that $P(0) = 0$, $P(1) = 0$, and $P(2) = 1$. 

	\vspace{7cm}
	% Strategy is to count failures! So, we look at the complement. 

\end{frame}

\begin{frame}
	\frametitle{$\mu t < y$ is Primitive Recursive}

	Bounded minimisation of a primitive recursive predicate is primitive recursive. 

	$$\mu t < y P(t) = \sum_{u < y}\prod_{t < u}\chi_{\lnot P}(t) $$

	\vspace{7cm}
	

\end{frame}

\section{Limitations of Primitive Recursion}

\begin{frame}
  \frametitle{Question}

	Can every function that is ``intuitively" computable be defined using the constructions of primitive recursive functions? Is this a good definition of ``effective procedure"? 

	\vspace{0.5cm}

	Every step of a primitive recursive function is specified. We do not need any further instruction to carry out the computation of such a function. Furthermore, all primitive recursive functions have a finite number of steps. 

	\vspace{0.5cm}

	% But there are functions which can be argued to be effective, which are not able to be defined using the primitive recursive structure.  

\end{frame}

\begin{frame}
	\frametitle{Count All Functions}

	Are all functions $\mathbb{N}^{k} \rightarrow \mathbb{N}$ primitive recursive? 
	% There are uncountably many functions of this form. 
	% f: N -> N are uncountable in number. 
	% Suffices to consider f:N -> {0,1}
	% Such an f corresponds to a binary sequence. Diagonal out. 
	\vspace{7cm}

\end{frame}

\begin{frame}
	\frametitle{G\"{o}del Codes, Again!}

	Using a similar technique to G\"{o}del allows us to number the primitive recursive functions. We use powers of primes to associate numbers to the basic primitive recursive functions 

	\begin{itemize}
		\item $\#(Z) = 11$ 
		\item $\#(S) = 13$
		\item $\#(\pi_{i}^{k}) = (p_{k+6})^{i+1}$
	\end{itemize}

	\vspace{0.5cm}

	If $\#(g) = a$ and $\#(h) = b$, then $\#(g\circ h) = 2^{a}3^{b}$.

	\vspace{0.5cm}

	If $f$ is defined by recursion on $h$ with base case $g$, then we assign the code $\#(f) = 5^{a}7^{b}$

	\vspace{0.5cm}

	Decoding an integer is a primitive recursive process!

	\vspace{1cm}

	from \emph{Computability}, Epstein and Carnielli.

\end{frame}

\begin{frame}
	\frametitle{Conclusion}

	Just by this counting argument we see that there are more functions than there are primitive recursive functions. 

	\vspace{0.5cm}

	Perhaps the extra functions in our count are not computable? 

	\vspace{5cm}

\end{frame}

\begin{frame}
	\frametitle{Cantor's Diagonal Returns}

	The countability of the primitive recursive functions means we have a computable list of primitive recursive functions of one-variable $f_{0}, f_{1}, \dots , f_{n}, \dots $

	\vspace{0.5cm}

	We consider the function $g(n) = f_{n}(n) + 1$. 

	\vspace{5cm}

	% Is this computable? Yes. 
	% Is this primitive recursive? No! Not on the list. 

\end{frame}

\begin{frame}
	\frametitle{Non-Recursive, but Computable}

	Consider the function $h$ defined as follows 

	\begin{align*}
		h(0) &= f_{0}(0) + 1 \\
		h(1) &= f_{0}(1) + f_{1}(1) + 1 \\
		&\vdots \\
		h(n) &= f_{0}(n) + f_{1}(n) + \dots + f_{n}(n) + 1 \\
		&\vdots
	\end{align*}

	{\bf Question:} Is $h$ primitive recursive? 

	\vspace{3cm}

	% Is considered computable because the list of pr functions is. 

	% If $f$ is primitive recursive, then f = f_{n}. But then f_{n}(n) < h(n). So no primitive recursive function agrees with $h$ every where. Thus, $h$ is not primitive recursive. Actually disagrees with all x >= n.

\end{frame}

\begin{frame}
	\frametitle{Computation and Primitive Recursion}

	In this way we see that primitive recursion is different from the intuitive idea we have of an effective procedure. 

	\vspace{0.5cm}

	Others gave different ideas about what effective computation should mean. 

	\vspace{0.5cm}

	Stephen Kleene extended the notion of primitive recursion by adding in an unbounded search operator. 

	% We won't say much about this, other than state what it means. 
	% We will instead move onto talk about Turing machines. 

\end{frame}

\section{$\mu$-Recursion}

\begin{frame}
	\frametitle{Unbounded-Search}

	In search of a broader class of functions that we can't diagonalise out of we follow Kleene and drop the bound and define the $\mu$ operator. 

	\vspace{0.5cm}

	Given a recursive function $f(y,{\bf x})$ we define a new function denoted by $\mu f$ and defined as

	$$(\mu f)({\bf x}) = \text{min}\{t \ | \ f(t,{\bf x}) = 0 \text{ and } f(y,{\bf x}) \downarrow \forall y < t \} $$

	Thus returning the minimum zero of a function.
\end{frame}

\begin{frame}
	\frametitle{Is $\mu$ Computable?}

	% Because the predicate is primitive recursive, each step in the process is certainly computable. All of the instructions for the computation are given. 
	% However, the process may never end! 
	% So the requirement of termination is given up. 

\end{frame}

\begin{frame}
	\frametitle{Total v. Partial Functions}

	This suggests the following definitions: 

	\vspace{0.5cm}

	We say a function $f:\mathbb{N}^{k} \rightarrow \mathbb{N}$ is {\bf total} if there is a well-defined output for each input. 

	\vspace{0.5cm}

	If there exist ${\bf x} \in \mathbb{N}^{k}$ for which $f({\bf x})$ is not defined, then we say $f(x)$ is a {\bf partial} function.

	\vspace{0.5cm}

	The broadening of the allowable constructions yields functions which are not total; that is, computable functions which do not have a well-defined output. 


\end{frame}

\begin{frame}
	\frametitle{Total v. Partial Functions}
	% Introduce the notation on this slide. 

	If $\varphi$ is a recursive function, we still write $\varphi(x)$ to denote the process of applying $\varphi$ to $x$. However, $\varphi(x)$ may not denote any object; there may not be any output.  

	\vspace{0.5cm}

	If we know $\varphi(x)$ is defined, we denote this by $\varphi(x)\downarrow$
	
	\vspace{0.5cm}

	If we know $\varphi(x)$ is undefined, we denote this by $\varphi(x)\cancel{\downarrow}$
\end{frame}

\begin{frame}
	\frametitle{$\mu$-Recursion}

	We can enumerate the general recursive functions:
	
	$$\varphi_{1}(x), \varphi_{2}(x), \dots \varphi_{n}(x), \dots $$ 
		
	We can write down $\psi(x) = \varphi_{x}(x) + 1$. 

	\vspace{5cm}

\end{frame}

\section{Modern Languages and Primitive Recursion}

\begin{frame}
	\frametitle{Engineering Machines}

	In parallel to these theoretical considerations, physicists and electrical engineers were constructing machines and their components to actually carry out more general computational procedures.  

	This is a different, equally interesting, story that we will not get to talk about in any great detail. Tutorial 1 gave you a small view into the developments in that direction. 

	However, to make this class of functions more tangible to our modern perspective, we will note how the general recursive functions relate to modern programming constructs. 

	In the 1960s Albert Meyer (Complexity Theory pioneer) and Dennis Ritchie (C, Unix) wrote a programming language, designed for an (abstract) register machine, which ``implements" this notion of computability.

\end{frame}

\begin{frame}
	\frametitle{Loop Programs}

	Loop, or For, programs are constructed using 

	\begin{enumerate}
		\item[] {\bf Var} = $x,y,z,...$
		\item[] Assignments $x:=0$, $x:=y+1$, $x:=y$
		\item[] Sequential composition $p;q$
		\item[] Loop $x$ do $p$ end
	\end{enumerate}

	Where the Loop $x$ do $p$ is interpreted as

	\begin{enumerate}
		\item[] At the start of the loop $x$ is determined.
		\item[] The loop-program $p$ is executed that many times. 
		\item[] Further changes to $x$ does not change the loop. 
		\item[] No decrement of $x$ required. 
	\end{enumerate}

	Meyer and Ritchie showed such programs are equivalent to the primitive recursive functions. 

\end{frame}

\begin{frame}
	\frametitle{Example}

	Addition: $x:= x + y$ 
	
	\vspace{0.5cm}

	\begin{enumerate}
		\item[] $x := a$; $y := b$;
		\item[] loop $y$ do 
		\item[] \hspace{0.5cm} $x := x + 1$
		\item[] end
	\end{enumerate}

	\vspace{5cm}



\end{frame}

\begin{frame}
	\frametitle{Example}

	Predecessor: $x:= y - 1$ 
	
	\vspace{0.5cm}

	\begin{enumerate}
		\item[] $x := 0$; $y := a$; $t = 0$;
		\item[] loop $y$ do 
		\item[] \hspace{0.5cm} $x := t$;
		\item[] \hspace{0.5cm} $t := t + 1$;
		\item[] end
	\end{enumerate}

	\vspace{5cm}


\end{frame}

\begin{frame}
	\frametitle{Example}

	Conditional Execution: If $x = 0$, then (do) $p$. 
	
	\vspace{0.5cm}

	\begin{enumerate}
		\item[] $x := a$; $t = 1$;
		\item[] loop $x$ do 
		\item[] \hspace{0.5cm} $t := 0$;
		\item[] end;
		\item[] loop $t$ do
		\item[] \hspace{0.5cm} $p$;
		\item[] end
	\end{enumerate}

	\vspace{5cm}

	
\end{frame}

\begin{frame}
	\frametitle{Example}

	If $x = 0$, then $p$, elif $x = 1$ do $q$, else do $r$. 
	
	% \vspace{0.5cm}

	% \begin{enumerate}
	% 	\item[] $x := a$; $t = 1$;
	% 	\item[] loop $x$ do 
	% 	\item[] \hspace{0.5cm} $t := 0$;
	% 	\item[] end;
	% 	\item[] loop $t$ do
	% 	\item[] \hspace{0.5cm} $p$;
	% 	\item[] end
	% \end{enumerate}

	\vspace{7cm}

	
\end{frame}


\begin{frame}
	\frametitle{Single Variable Recursion}

	Suppose $f(x)$ is defined recursively with base case $f(0) = 1$ and $f(x+1) = h(x,f(x))$ such that $h$ is primitive recursive and can be calculated by the Loop-program $H$. Provide a Loop-program, $F$, that calculates $f$. 

	\vspace{6cm}

\end{frame}

\begin{frame}
	\frametitle{While Programs}

	Let us define the while-construct as follows

	\begin{enumerate}
		\item[] while $x < y$ do $p$ end
	\end{enumerate}

	Where the condition $x < y$ is tested every loop and $p$ is executed until the condition is false. At which point the program control passes to the next instruction after the while-loop.

	\vspace{0.5cm}

	Adding this construct to the loop-programs gives programs that compute the general recursive class of functions. 

	\vspace{0.5cm}

	{\bf Note:} Loop construct is redundant in the presence of while.
	% do p x times using the following
	% x := a; 
	% t := 0; 
	% while t < x do 
	% 		p;
	%		t := t + 1;
	% end
	\vspace{3cm}


\end{frame}

\begin{frame}
	\frametitle{Further Reading}
	
	Here are some recommended reading to follow up on the lecture content.
	
	\vspace{0.5cm}
	
	\begin{itemize}
		\item SEP: Recursive Functions. 
		\item Computability, Richard Epstein. 
		\item Computability Theory, Enderton.
		\item Lectures on the Philosophy of Mathematics, Joel Hamkins.		
	\end{itemize}
	
\end{frame}
\end{document}
